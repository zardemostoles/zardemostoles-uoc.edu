{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zardemostoles/zardemostoles-uoc.edu/blob/master/TFG_Calculo_Tipo_Tono_Piel_ITA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de módulos que se emplean en el notebook"
      ],
      "metadata": {
        "id": "jDTG_TdHUNla"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "39QIcgoLQdGV"
      },
      "outputs": [],
      "source": [
        "# Se importan los módulos que se van a utilizar en el notebook\n",
        "\n",
        "# Módulos básicos\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Módulos de tratamiento de imágenes\n",
        "import PIL\n",
        "import cv2\n",
        "from skimage import io, color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JmYJxex2W97",
        "outputId": "f3544a50-afde-48e6-f62c-4bee8dd00af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n",
            "2.9.0\n"
          ]
        }
      ],
      "source": [
        "# Se comprueba la versión de TensorFlow\n",
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)\n",
        "\n",
        "# Preprocesamiento y entrenamiento de TensorFlow (prefetch) automático\n",
        "AUTO = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se monta el Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLhO8NjjUkn_",
        "outputId": "85a58060-e6c1-4f31-97d8-5d9a62455065"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YovdVhRjJ5jh"
      },
      "source": [
        "## Definición de funciones\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GvbTEm_9fIY"
      },
      "source": [
        "### Funciones de tratamiento de TFRecords y Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uSOWv-UGKOW4"
      },
      "outputs": [],
      "source": [
        "# Función para convertir una imagen en un tensor, creando un tensor con las \n",
        "# dimensiones requeridas y normalizado.\n",
        "# image: representación RGB de la imagen \n",
        "# size: dimensiones del tensor a los que se redimensiona (variable global)\n",
        "def prepare_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    # Dimensiona a las dimensiones del tensor\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "    # Normaliza los pixeles en el rango [0, 1]\n",
        "    image = tf.cast(image, tf.float32) / 255.0 \n",
        "    return image\n",
        "\n",
        "# Función para extraer de un TFRecord la imagen, el nombre de la imagen y \n",
        "# el diagnóstico.\n",
        "def read_labeled_tfrecord_with_file_name(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), \n",
        "        \"image_name\": tf.io.FixedLenFeature([], tf.string),  \n",
        "        \"patient_id\": tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"sex\": tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"age_approx\": tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"anatom_site_general_challenge\": tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"diagnosis\": tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"target\": tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    image = prepare_image(example['image'])\n",
        "    image_name = example['image_name']\n",
        "    target = tf.cast(example['target'], tf.int32)\n",
        "    return image, image_name, target\n",
        "\n",
        "\n",
        "# Función para filtrar los registros cuyo nombre de imágen no termine con\n",
        "# '_downsample'\n",
        "def filter_images(image, image_name, target):\n",
        "  return not tf.strings.regex_full_match(image_name,\"^((.*_downsampled))\")\n",
        "\n",
        "# Función para filtrar los registros con diagnóstico de melanoma\n",
        "def filter_images_melanoma(image, image_name, target):\n",
        "  return target == 1\n",
        "\n",
        "# Función para filtrar los registros con diagnóstico de no melanoma\n",
        "def filter_images_no_melanoma(image, image_name, target):\n",
        "  return target == 0\n",
        "\n",
        "# Función para suprimir el nombre del fichero de los registros\n",
        "def remove_file_name(image, file, target):\n",
        "  return image, target\n",
        "\n",
        "# Función para cargar en un dataset los TFRecords de un conjunto de registros\n",
        "def load_dataset(filenames):\n",
        "    # Lecturas en paralelo\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "    # Construye el dataset con el formato definido,\n",
        "    # descartando los que sean 'downsample'\n",
        "    dataset = dataset.map(read_labeled_tfrecord_with_file_name, \n",
        "                          num_parallel_calls=AUTO).filter(filter_images)\n",
        "    # Devuekve un dataset con (image, image_name, target)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones para cálculo del tipo de tono de piel ITA"
      ],
      "metadata": {
        "id": "BzI0zHv4pC8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecting Melanoma Fairly: Skin Tone Detection and Debiasing \n",
        "# for Skin Lesion Classification\n",
        "# https://github.com/pbevan1/Detecting-Melanoma-Fairly/blob/main/preprocessing.py\n",
        "# Hair removal for ITA calculation\n",
        "def hair_remove(image):\n",
        "    # Convert image to grayScale\n",
        "    grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    # Kernel for morphologyEx\n",
        "    kernel = cv2.getStructuringElement(1, (17, 17))\n",
        "    # Apply MORPH_BLACKHAT to grayScale image\n",
        "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
        "    # Apply thresholding to blackhat\n",
        "    _, threshold = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
        "    # Inpaint with original image and threshold image\n",
        "    final_image = cv2.inpaint(image, threshold, 1, cv2.INPAINT_TELEA)\n",
        "    return final_image\n",
        "\n",
        "# Calculates Fitzpatrick skin type of an image using Kinyanjui et al.'s thresholds\n",
        "def get_sample_ita_kin(img):\n",
        "    ita_bnd_kin = -1\n",
        "    try:\n",
        "        rgb = img\n",
        "        rgb = hair_remove(rgb)\n",
        "        lab = color.rgb2lab(rgb)\n",
        "        ita_lst = []\n",
        "        ita_bnd_lst = []\n",
        "\n",
        "        # Taking samples from different parts of the image\n",
        "        L1 = lab[230:250, 115:135, 0].mean()\n",
        "        b1 = lab[230:250, 115:135, 2].mean()\n",
        "\n",
        "        L2 = lab[5:25, 115:135, 0].mean()\n",
        "        b2 = lab[5:25, 115:135, 2].mean()\n",
        "\n",
        "        L3 = lab[115:135, 5:25, 0].mean()\n",
        "        b3 = lab[115:135, 5:25, 2].mean()\n",
        "\n",
        "        L4 = lab[115:135, 230:250, 0].mean()\n",
        "        b4 = lab[115:135, 230:250, 2].mean()\n",
        "\n",
        "        L5 = lab[216:236, 216:236, 0].mean()\n",
        "        b5 = lab[216:236, 216:236, 2].mean()\n",
        "\n",
        "        L6 = lab[216:236, 20:40, 0].mean()\n",
        "        b6 = lab[216:236, 20:40, 2].mean()\n",
        "\n",
        "        L7 = lab[20:40, 20:40, 0].mean()\n",
        "        b7 = lab[20:40, 20:40, 2].mean()\n",
        "\n",
        "        L8 = lab[20:40, 216:236, 0].mean()\n",
        "        b8 = lab[20:40, 216:236, 2].mean()\n",
        "\n",
        "        L_lst = [L1, L2, L3, L4, L5, L6, L7, L8]\n",
        "        b_lst = [b1, b2, b3, b4, b5, b6, b7, b8]\n",
        "\n",
        "        # Calculating ITA values\n",
        "        for L, b in zip(L_lst, b_lst):\n",
        "            ita = math.atan((L - 50) / b) * (180 / math.pi)\n",
        "            ita_lst.append(ita)\n",
        "\n",
        "        # Using max ITA value (lightest)\n",
        "        ita_max = max(ita_lst)\n",
        "\n",
        "        # Getting skin shade band from ITA\n",
        "        if ita_max > 55:\n",
        "            ita_bnd_kin = 1\n",
        "        if 41 < ita_max <= 55:\n",
        "            ita_bnd_kin = 2\n",
        "        if 28 < ita_max <= 41:\n",
        "            ita_bnd_kin = 3\n",
        "        if 19 < ita_max <= 28:\n",
        "            ita_bnd_kin = 4\n",
        "        if 10 < ita_max <= 19:\n",
        "            ita_bnd_kin = 5\n",
        "        if ita_max <= 10:\n",
        "            ita_bnd_kin = 6\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return ita_bnd_kin"
      ],
      "metadata": {
        "id": "Ff2n6_RspHIa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehUUnEgc6Oum"
      },
      "source": [
        "### Funciones de visualización de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VNYoVEwq6TtU"
      },
      "outputs": [],
      "source": [
        "# Dots per Inch para mostrar imágenes en un monitor de resolución 1366x768\n",
        "MY_DPI = 96\n",
        "\n",
        "# Función que muestra en pantalla las imágenes contenidas en un dataset con\n",
        "# su correspondiente diagnóstico (etiqueta)\n",
        "def show_sample_images(thumb_size, ds):\n",
        "  for img, file, target in iter(ds):\n",
        "    plt.figure(figsize=(thumb_size/MY_DPI, thumb_size/MY_DPI), dpi=MY_DPI)\n",
        "    file_name = file.numpy().decode('ascii')\n",
        "    target_diag = \"Melanoma\" if target.numpy() else \"No melanoma\"\n",
        "    image = np.clip(img.numpy() * 255, 0, 255).astype(np.uint8)\n",
        "    image = hair_remove(image)\n",
        "    print(get_sample_ita_kin(image))\n",
        "    image = PIL.Image.fromarray(image)\n",
        "    print(\"File: {} Size: {} Diagnóstico: {}\".format(file_name, image.size,target_diag))\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "# Función para mostrar un mosaico con imágenes\n",
        "def show_mosaic_images(thumb_size, cols, rows, ds):\n",
        "    mosaic = PIL.Image.new(mode='RGB', size=(thumb_size*cols + (cols-1), thumb_size*rows + (rows-1)))\n",
        "    for idx, data in enumerate(iter(ds)):\n",
        "        img, target = data[0], data[1]\n",
        "        ix  = idx % cols\n",
        "        iy  = idx // cols\n",
        "        img = np.clip(img.numpy() * 255, 0, 255).astype(np.uint8)\n",
        "        img = hair_remove(img)\n",
        "        img = PIL.Image.fromarray(img)\n",
        "        img = img.resize((thumb_size, thumb_size), resample=PIL.Image.BILINEAR)\n",
        "        mosaic.paste(img, (ix*thumb_size + ix, \n",
        "                           iy*thumb_size + iy))\n",
        "        if idx > cols*rows: break\n",
        "    display(mosaic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvwlmdXw7Naq"
      },
      "source": [
        "## Configuración del entorno hardware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiMABq9B7S9H",
        "outputId": "a69d0ab1-4225-4eb3-f742-8dddfd0afcea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU disponible  grpc://10.107.29.162:8470\n",
            "Réplicas: 8\n",
            "Tamaño de batch: 128\n"
          ]
        }
      ],
      "source": [
        "# Detecta hardware, devuelve la estrategia de distribución apropiada el HW.\n",
        "try:\n",
        "    # TPU detectada \n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('TPU disponible ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "else:\n",
        "    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    print(\"GPUs disponibles: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "print(\"Réplicas:\", strategy.num_replicas_in_sync)\n",
        "\n",
        "# Configura el tamaño del batch\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "print(\"Tamaño de batch:\", BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89wn44ve8frW"
      },
      "source": [
        "## Carga de los ficheros de TFRecords en datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgHilBmkLGGB",
        "outputId": "2e1e2a4a-3373-4df3-e025-803cfcd4f253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolución: 256x256, path: gs://kds-dffbfdcb6ca951891c5be0f6c65fef4772c9b97e418bf13d4744901b\n",
            "Ficheros TFRecord: (30)\n"
          ]
        }
      ],
      "source": [
        "# Ruta a los ficheros de TFRecords en GCS\n",
        "GCS_PATHS = {\n",
        "  \"256x256\": \"gs://kds-dffbfdcb6ca951891c5be0f6c65fef4772c9b97e418bf13d4744901b\",\n",
        "}\n",
        "\n",
        "# Resoluciones que se van a utilizar para el entrenamiento del modelo\n",
        "RESOLUTIONS = {\n",
        "  \"256x256\": [256, 256]\n",
        "}\n",
        "\n",
        "# Resolución del imágenes modelo\n",
        "MODEL_RESOLUTION = \"256x256\"\n",
        "IMAGE_SIZE = RESOLUTIONS[MODEL_RESOLUTION]\n",
        "\n",
        "# Carga los TFRecords \n",
        "dataset_files = {}\n",
        "for resolution, path in GCS_PATHS.items():\n",
        "    print(\"Resolución: {}, path: {}\".format(resolution, path))\n",
        "    dataset_files[resolution] = tf.io.gfile.glob(path + '/train*.tfrec')\n",
        "    print(\"Ficheros TFRecord: ({})\".format(len(dataset_files[resolution])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEFA0tJALiTj",
        "outputId": "df01ffc3-962a-4d82-aed7-e1f8945fd3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256x256 <FilterDataset element_spec=(TensorSpec(shape=(256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "# Carga de los conjuntos de datos desde los ficheros TFRecord\n",
        "full_datasets = {}\n",
        "for resolution, files in dataset_files.items():\n",
        "  IMAGE_SIZE = RESOLUTIONS[MODEL_RESOLUTION]\n",
        "  full_datasets[resolution] = load_dataset(files)\n",
        "  print(resolution, full_datasets[resolution])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R0lJhl_21cO"
      },
      "source": [
        "## Cálculo de tono de piel ITA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepara un fichero CSV con el nombre del fichero de fotografía, \n",
        "# y el tono de piel ITA\n",
        "import csv  \n",
        "!mv /content/drive/MyDrive/TFG/TFG_mejor_modelo_pred.csv /content/drive/MyDrive/TFG/TFG_tono_piel_ITA.csv.back\n",
        "header = ['image_name', 'tipo_ITA']\n",
        "with open('/content/drive/MyDrive/TFG/TFG_tono_piel_ITA.csv', 'w', encoding='UTF8') as f:\n",
        "  writer = csv.writer(f)\n",
        "  # Cabecera\n",
        "  writer.writerow(header)\n",
        "  idx = 0\n",
        "  for img, file, target in iter(full_datasets[MODEL_RESOLUTION]):\n",
        "    image = np.clip(img.numpy() * 255, 0, 255).astype(np.uint8)\n",
        "    image = hair_remove(image)\n",
        "    ITA = get_sample_ita_kin(image)\n",
        "    writer.writerow([file.numpy().decode('ascii'), ITA])\n",
        "    idx = idx + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VynLEFUtNyDp",
        "outputId": "d51b9846-6af9-4826-8523-b7e79adf94ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/drive/MyDrive/TFG/TFG_mejor_modelo_pred.csv': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-3f86ba95c9aa>:58: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  ita = math.atan((L - 50) / b) * (180 / math.pi)\n",
            "Exception ignored in: <function Executor.__del__ at 0x7fac047420d0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n",
            "    self.wait()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n",
            "    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n",
            "tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook está inspirado por:\n",
        "- Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification <br>\n",
        "https://github.com/pbevan1/Detecting-Melanoma-Fairly/blob/main/preprocessing.py"
      ],
      "metadata": {
        "id": "7zjOYpY9e7Ur"
      }
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "13hHVXNrrf2nisxKSNJlsE33TX0_po3Bd",
      "authorship_tag": "ABX9TyP+nHhRmBq8HkaUXkrED0jo",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}